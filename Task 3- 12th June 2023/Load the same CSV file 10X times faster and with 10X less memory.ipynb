{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5133a42",
   "metadata": {},
   "source": [
    "Even when we have 1TB of Disk Storage, 8GB/16GB of RAM still pandas and much other data loading API struggles to load a 2GB file.\n",
    "\n",
    "This is because when a process requests for memory, memory is allocated in two ways:\n",
    "\n",
    "Contiguous Memory Allocation (consecutive blocks are assigned)\n",
    "Non Contiguous Memory Allocation(separate blocks at different locations)\n",
    "Pandas use Contiguous Memory to load data into RAM because read and write operations are must faster on RAM than Disk(or SSDs).\n",
    "\n",
    "Reading from SSDs: ~16,000 nanoseconds\n",
    "Reading from RAM: ~100 nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a71ae",
   "metadata": {},
   "source": [
    "Before going into multiprocessing & GPUs, etc… let us see how to use pd.read_csv() effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cbf0e",
   "metadata": {},
   "source": [
    "## 1. use cols:\n",
    "    Rather than loading data and removing unnecessary columns that aren’t useful when processing your data.\n",
    "    load only the useful columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eee9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea4ea71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Island</th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Dream</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Dream</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Dream</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Dream</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Island  CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "0    Torgersen          39.1         18.7          181.0    3750.0        0\n",
       "1    Torgersen          39.5         17.4          186.0    3800.0        0\n",
       "2    Torgersen          40.3         18.0          195.0    3250.0        0\n",
       "3    Torgersen           0.0          0.0            0.0       0.0        0\n",
       "4    Torgersen          36.7         19.3          193.0    3450.0        0\n",
       "..         ...           ...          ...            ...       ...      ...\n",
       "339      Dream          55.8         19.8          207.0    4000.0        2\n",
       "340      Dream          43.5         18.1          202.0    3400.0        2\n",
       "341      Dream          49.6         18.2          193.0    3775.0        2\n",
       "342      Dream          50.8         19.0          210.0    4100.0        2\n",
       "343      Dream          50.2         18.7          198.0    3775.0        2\n",
       "\n",
       "[344 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Pranay/Downloads/penguins2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1160737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Columns: 6 entries, Island to Species\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 34.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ee9e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4562c494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_cols = ['Island','BodyMass','Species']\n",
    "len(req_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4e29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", usecols=req_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a2bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Columns: 3 entries, Island to Species\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 26.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252277a8",
   "metadata": {},
   "source": [
    "## 2. Using correct dtypes for numerical data:\n",
    "Every column has it’s own dtype in a pandas DataFrame, for example, integers have int64, int32, int16 etc…\n",
    "\n",
    "int8 can store integers from -128 to 127.\n",
    "\n",
    "int16 can store integers from -32768 to 32767.\n",
    "\n",
    "int64 can store integers from -9223372036854775808 to .9223372036854775807.\n",
    "\n",
    "Pandas assign int64 to integer datatype by default, therefore by defining correct dtypes we can reduce memory usage significantly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff604f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BodyMass'].memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0923049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BodyMass'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "802760a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6300.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BodyMass'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539c507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\")\n",
    "\n",
    "# Fill missing values (NaN) with a specific value or method\n",
    "df_filled = df.fillna(value=0)  # Fill with 0\n",
    "\n",
    "# Save the filled dataframe to a new CSV file\n",
    "df_filled.to_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b284418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", dtype={\"BodyMass\": \"int16\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c8dad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BodyMass'].memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a0a719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2752 - 688)/2752*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0488e",
   "metadata": {},
   "source": [
    "## 3. Using correct dtypes for categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "048db514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BodyMass'].memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9b63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", dtype={\"BodyMass\": \"category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "828cb8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8430"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BodyMass'].memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48161f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.83867141162516"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8430-688)/8430*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91bef6",
   "metadata": {},
   "source": [
    "If your DataFrame contains lots of empty values or missing values or NANs you can reduce their memory footprint by converting them to Sparse Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b93fe",
   "metadata": {},
   "source": [
    "## 4. nrows, skip rows\n",
    "nrows The number of rows to read from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419afd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", nrows=1000)\n",
    "len(df)\n",
    "1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c137cbd",
   "metadata": {},
   "source": [
    " skiprows Line numbers to skip (0-indexed) or the number of lines to skip (int) at the start of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f3961b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be either list or first N rows.\n",
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", skiprows=[0,2,5]) \n",
    "# It might remove headings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe754c3b",
   "metadata": {},
   "source": [
    "## 5. Loading Data in Chunks:\n",
    "Memory Issues in pandas read_csv() are there for a long time. So one of the best workarounds to load large datasets is in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94f2834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876fff",
   "metadata": {},
   "source": [
    "### Check the total length after loading chunk by chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3629e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d7a95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "for chunk in df:\n",
    "    # Do some preprocessing to reduce the memory size of each chunk\n",
    "    total_len += len(chunk)\n",
    "print(total_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae1fc8",
   "metadata": {},
   "source": [
    "### concatnate each chunk one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161ded24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", iterator=True, chunksize=1000)  # gives TextFileReader\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b02559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d7a87",
   "metadata": {},
   "source": [
    "## 6. Multiprocessing using pandas:\n",
    "As pandas don’t have njobs variable to make use of multiprocessing power. we can utilize multiprocessinglibrary to handle chunk size operations asynchronously on multi-threads which can reduce the run time by half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8db9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "986570d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "Wall time: 13.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", chunksize=1000)\n",
    "total_length = 0\n",
    "for chunk in df:\n",
    "    total_length += len(chunk)\n",
    "print(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LARGE_FILE = \"C:/Users/Pranay/Downloads/penguins2.csv\"\n",
    "CHUNKSIZE = 100  # processing 1000 rows at a time\n",
    "\n",
    "def process_frame(df):\n",
    "    # process data frame\n",
    "    return len(df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    reader = pd.read_table(LARGE_FILE, chunksize=CHUNKSIZE)\n",
    "    pool = mp.Pool(4)  # use 4 processes\n",
    "\n",
    "    funclist = []\n",
    "    for df in reader:\n",
    "        # process each data frame\n",
    "        f = pool.apply_async(process_frame, [df])\n",
    "        funclist.append(f)\n",
    "\n",
    "    result = 0\n",
    "    for f in funclist:\n",
    "        result += f.get()  # no timeout specified\n",
    "\n",
    "    print(f\"There are {result} rows of data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27ed3e",
   "metadata": {},
   "source": [
    "## 7. Dask Instead of Pandas:\n",
    "It supports parallel computing and loads data faster than pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d49820e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.21 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Island</th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Dream</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Dream</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Dream</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Dream</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Island  CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "0    Torgersen          39.1         18.7          181.0    3750.0      0.0\n",
       "1    Torgersen          39.5         17.4          186.0    3800.0      0.0\n",
       "2    Torgersen          40.3         18.0          195.0    3250.0      0.0\n",
       "3    Torgersen           0.0          0.0            0.0       0.0      0.0\n",
       "4    Torgersen          36.7         19.3          193.0    3450.0      0.0\n",
       "..         ...           ...          ...            ...       ...      ...\n",
       "339      Dream          55.8         19.8          207.0    4000.0      2.0\n",
       "340      Dream          43.5         18.1          202.0    3400.0      2.0\n",
       "341      Dream          49.6         18.2          193.0    3775.0      2.0\n",
       "342      Dream          50.8         19.0          210.0    4100.0      2.0\n",
       "343      Dream          50.2         18.7          198.0    3775.0      2.0\n",
       "\n",
       "[344 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "import dask.dataframe as dd\n",
    "data = dd.read_csv(\"C:/Users/Pranay/Downloads/penguins2.csv\", dtype={'MachineHoursCurrentMeter': 'float64'},assume_missing=True)\n",
    "data.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1439cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
