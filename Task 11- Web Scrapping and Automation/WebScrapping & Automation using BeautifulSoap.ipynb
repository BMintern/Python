{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e16fa1a",
   "metadata": {},
   "source": [
    "## Web Scraping:\n",
    "It is the process of extracting data from websites by automating the retrieval and parsing of HTML (Hypertext Markup Language) code. It involves accessing web pages, retrieving the underlying HTML content, and then extracting specific information or data points from the HTML.\n",
    "\n",
    "Web scraping allows you to gather data from websites at scale, rather than manually copying and pasting information from individual web pages. By automating the process, you can extract data from multiple pages or even entire websites in a structured and efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9e93b",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "Beautiful Soup is a Python web scraping library that allows us to parse and scrape HTML and XML pages. You can search, navigate, and modify data using a parser. Itâ€™s versatile and saves a lot of time. In this article we will learn how to scrape data using Beautiful Soup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c38b8",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bf80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required Libraries\n",
    "import pandas as pd   #to create dataframe\n",
    "import requests       #to send the request to the URL\n",
    "from bs4 import BeautifulSoup #to get the content in the form of HTML\n",
    "import numpy as np  # to count the values (in our case)\n",
    "\n",
    "#assigning the URL with variable name url\n",
    "url = 'https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating'\n",
    "#request allow you to send HTTP request\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#creating an empty list, so that we can append the values\n",
    "movie_name = []\n",
    "year = []\n",
    "time = []\n",
    "rating = []\n",
    "metascore = []\n",
    "votes = []\n",
    "gross = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6ce11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the meaningfull required data in the variable\n",
    "movie_data = soup.findAll('div', attrs= {'class': 'lister-item mode-advanced'})\n",
    "\n",
    "#calling one by one using for loop\n",
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "\n",
    "    year_of_release = store.h3.find('span', class_ = 'lister-item-year text-muted unbold').text.replace('(', '').replace(')', '')\n",
    "    year.append(year_of_release)\n",
    "\n",
    "    runtime = store.p.find('span', class_ = 'runtime').text.replace(' min', '')\n",
    "    time.append(runtime)\n",
    "\n",
    "    rate = store.find('div', class_ = 'inline-block ratings-imdb-rating').text.replace('\\n', '')\n",
    "    rating.append(rate)\n",
    "\n",
    "    meta  = store.find('span', class_ = 'metascore').text.replace(' ', '') if store.find('span', class_ = 'metascore') else '^^^^^^'\n",
    "    metascore.append(meta)\n",
    "    #since, gross and votes have same attributes, that's why we had created a common variable and then used indexing\n",
    "    value = store.find_all('span', attrs = {'name': 'nv'})\n",
    "\n",
    "    vote = value[0].text\n",
    "    votes.append(vote)\n",
    "\n",
    "    grosses = value[1].text if len(value) >1 else '*****'\n",
    "    gross.append(grosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b02efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe using pandas library\n",
    "movie_DF = pd.DataFrame({'Name of movie': movie_name, 'Year of release': year, 'Watchtime': time, 'Movie Rating': rating, 'Metascore': metascore, 'Votes': votes, 'Gross collection': gross})\n",
    "movie_DF\n",
    "\n",
    "\n",
    "#Saving data in Excel file:\n",
    "movie_DF.to_excel(\"Top_100_IMDB_Movies.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f700920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Watchtime</th>\n",
       "      <th>Movie Rating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Gross collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>142</td>\n",
       "      <td>9.3</td>\n",
       "      <td>82</td>\n",
       "      <td>2,757,982</td>\n",
       "      <td>$28.34M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>175</td>\n",
       "      <td>9.2</td>\n",
       "      <td>100</td>\n",
       "      <td>1,919,137</td>\n",
       "      <td>$134.97M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2,730,947</td>\n",
       "      <td>$534.86M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>1993</td>\n",
       "      <td>195</td>\n",
       "      <td>9.0</td>\n",
       "      <td>95</td>\n",
       "      <td>1,389,930</td>\n",
       "      <td>$96.90M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>96</td>\n",
       "      <td>9.0</td>\n",
       "      <td>97</td>\n",
       "      <td>817,118</td>\n",
       "      <td>$4.36M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name of movie Year of release Watchtime Movie Rating Metascore  \\\n",
       "0  The Shawshank Redemption            1994       142          9.3        82   \n",
       "1             The Godfather            1972       175          9.2       100   \n",
       "2           The Dark Knight            2008       152          9.0        84   \n",
       "3          Schindler's List            1993       195          9.0        95   \n",
       "4              12 Angry Men            1957        96          9.0        97   \n",
       "\n",
       "       Votes Gross collection  \n",
       "0  2,757,982          $28.34M  \n",
       "1  1,919,137         $134.97M  \n",
       "2  2,730,947         $534.86M  \n",
       "3  1,389,930          $96.90M  \n",
       "4    817,118           $4.36M  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb8cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Watchtime</th>\n",
       "      <th>Movie Rating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Gross collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>96</td>\n",
       "      <td>II 2018</td>\n",
       "      <td>158</td>\n",
       "      <td>8.5</td>\n",
       "      <td>^^^^^^</td>\n",
       "      <td>33,352</td>\n",
       "      <td>*****</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name of movie Year of release Watchtime Movie Rating Metascore   Votes  \\\n",
       "58            96         II 2018       158          8.5    ^^^^^^  33,352   \n",
       "\n",
       "   Gross collection  \n",
       "58            *****  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = movie_DF[\"Year of release\"].max()\n",
    "\n",
    "movie_DF.loc[movie_DF[\"Year of release\"]==latest,[\"Name of movie\",\"Year of release\",\"Watchtime\",\"Movie Rating\",\"Metascore\",\"Votes\",\"Gross collection\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c609450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52340e63",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e404d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#the website URL\n",
    "url_link = \"https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States\"\n",
    "result = requests.get(url_link).text\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55551a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#import requests library\n",
    "import requests\n",
    "#the website URL\n",
    "url_link = \"https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States\"\n",
    "result = requests.get(url_link).text\n",
    "doc = BeautifulSoup(result, \"html.parser\")\n",
    "\n",
    "#print(doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a10d33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = doc.find(id = \"content\")\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10d46b",
   "metadata": {},
   "source": [
    "#### FIND ELEMENTS BY CLASS NAME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8277694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\"><span class=\"mw-page-title-main\">List of states and territories of the United States</span></h1>\n"
     ]
    }
   ],
   "source": [
    "heading = res.find(class_ = \"firstHeading\")\n",
    "print(heading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b635c",
   "metadata": {},
   "source": [
    "#### EXTRACTING TEXT FROM HTML ELEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6edd6556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of states and territories of the United States\n"
     ]
    }
   ],
   "source": [
    "print(heading.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abd825b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_link=\"https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States\"\n",
    "\n",
    "result=requests.get(url_link).text\n",
    "\n",
    "doc=BeautifulSoup(result, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cd8ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table=doc.find(\"table\", class_=\"wikitable sortable plainrowheaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bc92046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postal abbreviation', '[8]', '[A]', '[10]', '[11]', '[11]', '[11]', None, '[12]', 'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', '[B]', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', '[B]', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', '[B]', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', '[B]', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n"
     ]
    }
   ],
   "source": [
    "th_tags = my_table.find_all('th')\n",
    "names = []\n",
    "for elem in th_tags:\n",
    "    a_links = elem.find_all(\"a\")\n",
    "    # Getting the text inside the <a> tag\n",
    "    for i in a_links:\n",
    "        names.append(i.string)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d16e131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', '[B]', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', '[B]', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', '[B]', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', '[B]', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
      "Checking string: 'Alabama'\n",
      "Checking string: 'Alaska'\n",
      "Checking string: 'Arizona'\n",
      "Checking string: 'Arkansas'\n",
      "Checking string: 'California'\n",
      "Checking string: 'Colorado'\n",
      "Checking string: 'Connecticut'\n",
      "Checking string: 'Delaware'\n",
      "Checking string: 'Florida'\n",
      "Checking string: 'Georgia'\n",
      "Checking string: 'Hawaii'\n",
      "Checking string: 'Idaho'\n",
      "Checking string: 'Illinois'\n",
      "Checking string: 'Indiana'\n",
      "Checking string: 'Iowa'\n",
      "Checking string: 'Kansas'\n",
      "Checking string: 'Kentucky'\n",
      "Checking string: '[B]'\n",
      "Checking string: 'Louisiana'\n",
      "Checking string: 'Maine'\n",
      "Checking string: 'Maryland'\n",
      "Checking string: 'Massachusetts'\n",
      "Checking string: '[B]'\n",
      "Checking string: 'Michigan'\n",
      "Checking string: 'Minnesota'\n",
      "Checking string: 'Mississippi'\n",
      "Checking string: 'Missouri'\n",
      "Checking string: 'Montana'\n",
      "Checking string: 'Nebraska'\n",
      "Checking string: 'Nevada'\n",
      "Checking string: 'New Hampshire'\n",
      "Checking string: 'New Jersey'\n",
      "Checking string: 'New Mexico'\n",
      "Checking string: 'New York'\n",
      "Checking string: 'North Carolina'\n",
      "Checking string: 'North Dakota'\n",
      "Checking string: 'Ohio'\n",
      "Checking string: 'Oklahoma'\n",
      "Checking string: 'Oregon'\n",
      "Checking string: 'Pennsylvania'\n",
      "Checking string: '[B]'\n",
      "Checking string: 'Rhode Island'\n",
      "Checking string: 'South Carolina'\n",
      "Checking string: 'South Dakota'\n",
      "Checking string: 'Tennessee'\n",
      "Checking string: 'Texas'\n",
      "Checking string: 'Utah'\n",
      "Checking string: 'Vermont'\n",
      "Checking string: 'Virginia'\n",
      "Checking string: '[B]'\n",
      "Checking string: 'Washington'\n",
      "Checking string: 'West Virginia'\n",
      "Checking string: 'Wisconsin'\n",
      "Checking string: 'Wyoming'\n",
      "['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n"
     ]
    }
   ],
   "source": [
    "final_list = names[9:]\n",
    "states = []\n",
    "print(final_list)  # Debug print statement\n",
    "for string in final_list:\n",
    "    print(f\"Checking string: '{string}'\")  # Debug print statement\n",
    "    if len(string.lower()) > 3:  # Convert to lowercase for comparison\n",
    "        states.append(string)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fbe7b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5,024,279', '7', '733,391', '1', '7,151,502', '9', '3,011,524', '4', '39,538,223', '52', '5,773,714', '8', '3,605,944', '5', '989,948', '1', '21,538,187', '28', '10,711,908', '14', '1,455,271', '2', '1,839,106', '2', '12,812,508', '17', '6,785,528', '9', '3,190,369', '4', '2,937,880', '4', '4,505,836', '6', '4,657,757', '6', '1,362,359', '2', '6,177,224', '8', '7,029,917', '9', '10,077,331', '13', '5,706,494', '8', '2,961,279', '4', '6,154,913', '8', '1,084,225', '2', '1,961,504', '3', '3,104,614', '4', '1,377,529', '2', '9,288,994', '12', '2,117,522', '3', '20,201,249', '26', '10,439,388', '14', '779,094', '1', '11,799,448', '15', '3,959,353', '5', '4,237,256', '6', '13,002,700', '17', '1,097,379', '2', '5,118,425', '7', '886,667', '1', '6,910,840', '9', '29,145,505', '38', '3,271,616', '4', '643,077', '1', '8,631,393', '11', '7,705,281', '10', '1,793,716', '2', '5,893,718', '8', '576,851', '1']\n"
     ]
    }
   ],
   "source": [
    "divs = my_table.find_all(\"div\")\n",
    "pop = []\n",
    "for i in divs:\n",
    "    pop.append(i.string)\n",
    "print(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f4706f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5,024,279', '733,391', '7,151,502', '3,011,524', '39,538,223', '5,773,714', '3,605,944', '989,948', '21,538,187', '10,711,908', '1,455,271', '1,839,106', '12,812,508', '6,785,528', '3,190,369', '2,937,880', '4,505,836', '4,657,757', '1,362,359', '6,177,224', '7,029,917', '10,077,331', '5,706,494', '2,961,279', '6,154,913', '1,084,225', '1,961,504', '3,104,614', '1,377,529', '9,288,994', '2,117,522', '20,201,249', '10,439,388', '779,094', '11,799,448', '3,959,353', '4,237,256', '13,002,700', '1,097,379', '5,118,425', '886,667', '6,910,840', '29,145,505', '3,271,616', '643,077', '8,631,393', '7,705,281', '1,793,716', '5,893,718', '576,851']\n"
     ]
    }
   ],
   "source": [
    "pop_final = []\n",
    "for i in pop:\n",
    "    if len(i) > 3:\n",
    "        pop_final.append(i)\n",
    "print(pop_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "693deaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             state  population\n",
      "0          Alabama   5,024,279\n",
      "1           Alaska     733,391\n",
      "2          Arizona   7,151,502\n",
      "3         Arkansas   3,011,524\n",
      "4       California  39,538,223\n",
      "5         Colorado   5,773,714\n",
      "6      Connecticut   3,605,944\n",
      "7         Delaware     989,948\n",
      "8          Florida  21,538,187\n",
      "9          Georgia  10,711,908\n",
      "10          Hawaii   1,455,271\n",
      "11           Idaho   1,839,106\n",
      "12        Illinois  12,812,508\n",
      "13         Indiana   6,785,528\n",
      "14            Iowa   3,190,369\n",
      "15          Kansas   2,937,880\n",
      "16        Kentucky   4,505,836\n",
      "17       Louisiana   4,657,757\n",
      "18           Maine   1,362,359\n",
      "19        Maryland   6,177,224\n",
      "20   Massachusetts   7,029,917\n",
      "21        Michigan  10,077,331\n",
      "22       Minnesota   5,706,494\n",
      "23     Mississippi   2,961,279\n",
      "24        Missouri   6,154,913\n",
      "25         Montana   1,084,225\n",
      "26        Nebraska   1,961,504\n",
      "27          Nevada   3,104,614\n",
      "28   New Hampshire   1,377,529\n",
      "29      New Jersey   9,288,994\n",
      "30      New Mexico   2,117,522\n",
      "31        New York  20,201,249\n",
      "32  North Carolina  10,439,388\n",
      "33    North Dakota     779,094\n",
      "34            Ohio  11,799,448\n",
      "35        Oklahoma   3,959,353\n",
      "36          Oregon   4,237,256\n",
      "37    Pennsylvania  13,002,700\n",
      "38    Rhode Island   1,097,379\n",
      "39  South Carolina   5,118,425\n",
      "40    South Dakota     886,667\n",
      "41       Tennessee   6,910,840\n",
      "42           Texas  29,145,505\n",
      "43            Utah   3,271,616\n",
      "44         Vermont     643,077\n",
      "45        Virginia   8,631,393\n",
      "46      Washington   7,705,281\n",
      "47   West Virginia   1,793,716\n",
      "48       Wisconsin   5,893,718\n",
      "49         Wyoming     576,851\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['state'] = states\n",
    "df['population'] = pop_final\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac21ff8",
   "metadata": {},
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1f38600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install requests\n",
    "import requests\n",
    "\n",
    "# pip3 install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# pip3 install pandas\n",
    "import pandas as pd\n",
    "\n",
    "books = []\n",
    "\n",
    "for i in range(1,5):\n",
    "    url = f\"https://books.toscrape.com/catalogue/page-{i}.html\"\n",
    "    response = requests.get(url)\n",
    "    response = response.content\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    ol = soup.find('ol')\n",
    "    articles = ol.find_all('article', class_='product_pod')\n",
    "for article in articles:\n",
    "    image = article.find('img')\n",
    "    title = image.attrs['alt']\n",
    "    starTag = article.find('p')\n",
    "    star = starTag['class'][1]\n",
    "    price = article.find('p', class_='price_color').text\n",
    "    price = float(price[1:])\n",
    "    books.append([title, star, price])\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(books, columns=['Title', 'Star Rating', 'Price'])\n",
    "df.to_csv('books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48c74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a59e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
